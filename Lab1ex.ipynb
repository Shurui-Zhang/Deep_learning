{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab1ex.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMUeKMoFBqVg6a/rQ1GOT6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shurui-Zhang/Deep_learning/blob/main/Lab1ex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BgCJ4rObznq"
      },
      "source": [
        "from typing import Tuple\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def sgd_factorise(A:torch.Tensor, rank:int, num_epochs =1000, lr =0.01) -> Tuple[torch.Tensor, torch. Tensor]:\n",
        "  \n",
        "  m, n = A.shape\n",
        "  r = rank\n",
        "\n",
        "  U = torch.normal(0, 1, size=(m, r))\n",
        "  V = torch.normal(0, 1, size=(n, r))\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for row in range(m):\n",
        "      for column in range(n):\n",
        "        error = A[row, column] - U[row, :] @ V[column, :].t()\n",
        "        U[row, :] = U[row, :] + lr * error * V[column, :]\n",
        "        V[column, :] = V[column, :] + lr * error * U[row, :]\n",
        "  \n",
        "  return U, V\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv0G9_2sceLl",
        "outputId": "bd40430d-384f-4a89-e1bf-09f180dc04f2"
      },
      "source": [
        "z = torch.tensor([[0.3374, 0.6005, 0.1735], [3.3359, 0.0492, 1.8374], [2.9407, 0.5301, 2.2620]], dtype=torch.float)\n",
        "print(np.linalg.matrix_rank(z))\n",
        "U, V = sgd_factorise(z, 2)\n",
        "print(\"U = \", U)\n",
        "print(\"V = \", V)\n",
        "print(\"error =\", torch.nn.functional.mse_loss(U@V.t(), z, reduction='sum'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "U =  tensor([[ 0.1509, -0.1521],\n",
            "        [ 1.6671,  0.0970],\n",
            "        [ 1.5327, -0.3966]])\n",
            "V =  tensor([[ 1.9936,  0.3157],\n",
            "        [ 0.1311, -0.6856],\n",
            "        [ 1.1526, -1.3099]])\n",
            "error = tensor(0.2907)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0berIXhGp5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f04f37c-aef8-4a9d-fef6-7de43f3b67cb"
      },
      "source": [
        "z_svd = torch.svd(z)\n",
        "print(z_svd)\n",
        "print(z_svd[0] @ torch.diag(z_svd[1]) @ z_svd[2].t() )\n",
        "z_svd[1][2] = 0\n",
        "print(\"the result of using torch.svd:\")\n",
        "print(z_svd)\n",
        "print(\"the result of reconstruction:\")\n",
        "print(z_svd[0] @ torch.diag(z_svd[1]) @ z_svd[2].t())\n",
        "print(\"error = \", torch.nn.functional.mse_loss(z_svd[0] @ torch.diag(z_svd[1]) @ z_svd[2].t(), z, reduction='sum'))\n",
        "print(z_svd[0] @ z_svd[0].t())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.return_types.svd(\n",
            "U=tensor([[-0.0801, -0.7448,  0.6625],\n",
            "        [-0.7103,  0.5090,  0.4863],\n",
            "        [-0.6994, -0.4316, -0.5697]]),\n",
            "S=tensor([5.3339, 0.6959, 0.3492]),\n",
            "V=tensor([[-0.8349,  0.2548,  0.4879],\n",
            "        [-0.0851, -0.9355,  0.3430],\n",
            "        [-0.5439, -0.2448, -0.8027]]))\n",
            "tensor([[0.3374, 0.6005, 0.1735],\n",
            "        [3.3359, 0.0492, 1.8374],\n",
            "        [2.9407, 0.5301, 2.2620]])\n",
            "the result of using torch.svd:\n",
            "torch.return_types.svd(\n",
            "U=tensor([[-0.0801, -0.7448,  0.6625],\n",
            "        [-0.7103,  0.5090,  0.4863],\n",
            "        [-0.6994, -0.4316, -0.5697]]),\n",
            "S=tensor([5.3339, 0.6959, 0.0000]),\n",
            "V=tensor([[-0.8349,  0.2548,  0.4879],\n",
            "        [-0.0851, -0.9355,  0.3430],\n",
            "        [-0.5439, -0.2448, -0.8027]]))\n",
            "the result of reconstruction:\n",
            "tensor([[ 0.2245,  0.5212,  0.3592],\n",
            "        [ 3.2530, -0.0090,  1.9737],\n",
            "        [ 3.0378,  0.5983,  2.1023]])\n",
            "error =  tensor(0.1219)\n",
            "tensor([[1.0000e+00, 3.1216e-07, 1.2579e-07],\n",
            "        [3.1216e-07, 1.0000e+00, 1.4313e-07],\n",
            "        [1.2579e-07, 1.4313e-07, 1.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9MpGCgoYTif"
      },
      "source": [
        "def sgd_factorise_masked(A:torch.Tensor, M: torch.Tensor, rank:int, num_epochs =1000, lr =0.01) -> Tuple[torch.Tensor, torch. Tensor]:\n",
        "  \n",
        "  m, n = A.shape\n",
        "  r = rank\n",
        "\n",
        "  U = torch.normal(0, 1, size=(m, r))\n",
        "  V = torch.normal(0, 1, size=(n, r))\n",
        "  print(\"initial metricx\",U@V.t())\n",
        "  for epoch in range(num_epochs):\n",
        "    for row in range(m):\n",
        "      for column in range(n):\n",
        "        if M[row, column] == 1:\n",
        "          error = A[row, column] - U[row, :] @ V[column, :].t()\n",
        "          U[row, :] = U[row, :] + lr * error * V[column, :]\n",
        "          V[column, :] = V[column, :] + lr * error * U[row, :]\n",
        "  \n",
        "  return U, V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nY9qdWHOQ61",
        "outputId": "48d23071-2ec4-4f31-ed3c-65266bcd6e5e"
      },
      "source": [
        "original_matrix = torch.tensor([[0.3374, 0.6005, 0.1735], [0, 0.0492, 1.8374], [2.9407, 0, 2.2620]], dtype=torch.float)\n",
        "mask_matrix = torch.tensor([[1, 1, 1], [0, 1, 1], [1, 0, 1]], dtype=torch.float)\n",
        "U_2, V_2 = sgd_factorise_masked(original_matrix, mask_matrix, 3)\n",
        "#print(\"U = \", U_2)\n",
        "#print(\"V = \", V_2)\n",
        "completed_matrix = U@V.t()\n",
        "print(\"the original matrix:\")\n",
        "print(z)\n",
        "print(\"the matrix after reconstruction:\")\n",
        "print(completed_matrix)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial metricx tensor([[-4.0649, -0.7557,  2.8187],\n",
            "        [-2.2092, -3.5939, -0.8702],\n",
            "        [ 1.3050, -2.4338, -2.4134]])\n",
            "the original matrix:\n",
            "tensor([[0.3374, 0.6005, 0.1735],\n",
            "        [3.3359, 0.0492, 1.8374],\n",
            "        [2.9407, 0.5301, 2.2620]])\n",
            "the matrix after reconstruction:\n",
            "tensor([[0.2528, 0.1241, 0.3732],\n",
            "        [3.3542, 0.1520, 1.7944],\n",
            "        [2.9304, 0.4728, 2.2861]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDhnCJrASunm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}